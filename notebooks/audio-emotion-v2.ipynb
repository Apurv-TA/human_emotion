{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import glob \n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-11T08:30:16.911684Z",
     "iopub.status.busy": "2022-03-11T08:30:16.911420Z",
     "iopub.status.idle": "2022-03-11T08:30:20.344871Z",
     "shell.execute_reply": "2022-03-11T08:30:20.344156Z",
     "shell.execute_reply.started": "2022-03-11T08:30:16.911652Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_SAVEE(\n",
    "    SAVEE = \"data/raw/SAVEE/\"\n",
    "):\n",
    "    dir_list = sorted(os.listdir(SAVEE))\n",
    "\n",
    "    emotion=[]\n",
    "    path = []\n",
    "    for i in dir_list:\n",
    "        if i[-8:-6]=='_a':\n",
    "            emotion.append('male_angry')\n",
    "        elif i[-8:-6]=='_d':\n",
    "            emotion.append('male_disgust')\n",
    "        elif i[-8:-6]=='_f':\n",
    "            emotion.append('male_fear')\n",
    "        elif i[-8:-6]=='_h':\n",
    "            emotion.append('male_happy')\n",
    "        elif i[-8:-6]=='_n':\n",
    "            emotion.append('male_neutral')\n",
    "        elif i[-8:-6]=='sa':\n",
    "            emotion.append('male_sad')\n",
    "        elif i[-8:-6]=='su':\n",
    "            emotion.append('male_surprise')\n",
    "        else:\n",
    "            emotion.append('male_error') \n",
    "        path.append(SAVEE + i)\n",
    "\n",
    "    SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "    SAVEE_df['source'] = 'SAVEE'\n",
    "    SAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "    \n",
    "    print(\n",
    "        f\"SAVEE_df:\\n{SAVEE_df['labels'].value_counts()}\",\n",
    "        end=\"\\n\" + \"-\" * 100 + \"\\n\"\n",
    "    )\n",
    "\n",
    "    return SAVEE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_RAVDESS(\n",
    "    RAVDESS = \"data/raw/RAVDESS/audio_speech_actors_01-24/\"\n",
    "):\n",
    "    dir_list = sorted(os.listdir(RAVDESS))\n",
    "\n",
    "    emotion = []\n",
    "    gender = []\n",
    "    path = []\n",
    "    for i in dir_list:\n",
    "        fname = os.listdir(RAVDESS + i)\n",
    "        for f in fname:\n",
    "            part = f.split('.')[0].split('-')\n",
    "            emotion.append(int(part[2]))\n",
    "            temp = int(part[6])\n",
    "            if temp%2 == 0:\n",
    "                temp = \"female\"\n",
    "            else:\n",
    "                temp = \"male\"\n",
    "            gender.append(temp)\n",
    "            path.append(RAVDESS + i + '/' + f)\n",
    "\n",
    "        \n",
    "    RAVDESS_df = pd.DataFrame(emotion)\n",
    "    RAVDESS_df = RAVDESS_df.replace(\n",
    "        {1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n",
    "    )\n",
    "    RAVDESS_df = pd.concat([pd.DataFrame(gender),RAVDESS_df],axis=1)\n",
    "    RAVDESS_df.columns = ['gender','emotion']\n",
    "    RAVDESS_df['labels'] =RAVDESS_df.gender + '_' + RAVDESS_df.emotion\n",
    "    RAVDESS_df['source'] = 'RAVDESS'  \n",
    "    RAVDESS_df = pd.concat([RAVDESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "    RAVDESS_df = RAVDESS_df.drop(['gender', 'emotion'], axis=1)\n",
    "    \n",
    "    print(\n",
    "        f\"RAVDESS_df:\\n{RAVDESS_df['labels'].value_counts()}\",\n",
    "        end=\"\\n\" + \"-\" * 100 + \"\\n\"\n",
    "    )\n",
    "    \n",
    "    return RAVDESS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T08:30:20.346802Z",
     "iopub.status.busy": "2022-03-11T08:30:20.346532Z",
     "iopub.status.idle": "2022-03-11T08:30:20.352873Z",
     "shell.execute_reply": "2022-03-11T08:30:20.352228Z",
     "shell.execute_reply.started": "2022-03-11T08:30:20.346768Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_TESS(\n",
    "    TESS = \"data/raw/TESS/TESS Toronto emotional speech set data/\"\n",
    "):\n",
    "    dir_list=sorted(os.listdir(TESS))\n",
    "    path = []\n",
    "    emotion = []\n",
    "\n",
    "    for i in dir_list:\n",
    "        fname = os.listdir(TESS + i)\n",
    "        for f in fname:\n",
    "            if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "                emotion.append('female_angry')\n",
    "            elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "                emotion.append('female_disgust')\n",
    "            elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "                emotion.append('female_fear')\n",
    "            elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "                emotion.append('female_happy')\n",
    "            elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "                emotion.append('female_neutral')                                \n",
    "            elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "                emotion.append('female_surprise')               \n",
    "            elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "                emotion.append('female_sad')\n",
    "            else:\n",
    "                emotion.append('Unknown')\n",
    "            path.append(TESS + i + \"/\" + f)\n",
    "\n",
    "    TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "    TESS_df['source'] = 'TESS'\n",
    "    TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "    \n",
    "    print(\n",
    "        f\"TESS_df:\\n{TESS_df['labels'].value_counts()}\",\n",
    "        end=\"\\n\" + \"-\" * 100 + \"\\n\"\n",
    "    )\n",
    "    \n",
    "    return TESS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_CREMA(\n",
    "    CREMA = \"data/raw/CREMA/\"\n",
    "):\n",
    "    dir_list = sorted(os.listdir(CREMA))\n",
    "\n",
    "    gender = []\n",
    "    emotion = []\n",
    "    path = []\n",
    "    female = [\n",
    "        1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,\n",
    "        1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,1052,\n",
    "        1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,\n",
    "        1076,1078,1079,1082,1084,1089,1091\n",
    "    ]\n",
    "\n",
    "    for i in dir_list: \n",
    "        part = i.split('_')\n",
    "        if int(part[0]) in female:\n",
    "            temp = 'female'\n",
    "        else:\n",
    "            temp = 'male'\n",
    "        gender.append(temp)\n",
    "        if part[2] == 'SAD' and temp == 'male':\n",
    "            emotion.append('male_sad')\n",
    "        elif part[2] == 'ANG' and temp == 'male':\n",
    "            emotion.append('male_angry')\n",
    "        elif part[2] == 'DIS' and temp == 'male':\n",
    "            emotion.append('male_disgust')\n",
    "        elif part[2] == 'FEA' and temp == 'male':\n",
    "            emotion.append('male_fear')\n",
    "        elif part[2] == 'HAP' and temp == 'male':\n",
    "            emotion.append('male_happy')\n",
    "        elif part[2] == 'NEU' and temp == 'male':\n",
    "            emotion.append('male_neutral')\n",
    "        elif part[2] == 'SAD' and temp == 'female':\n",
    "            emotion.append('female_sad')\n",
    "        elif part[2] == 'ANG' and temp == 'female':\n",
    "            emotion.append('female_angry')\n",
    "        elif part[2] == 'DIS' and temp == 'female':\n",
    "            emotion.append('female_disgust')\n",
    "        elif part[2] == 'FEA' and temp == 'female':\n",
    "            emotion.append('female_fear')\n",
    "        elif part[2] == 'HAP' and temp == 'female':\n",
    "            emotion.append('female_happy')\n",
    "        elif part[2] == 'NEU' and temp == 'female':\n",
    "            emotion.append('female_neutral')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(CREMA + i)\n",
    "    \n",
    "    CREMA_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "    CREMA_df['source'] = 'CREMA'\n",
    "    CREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "    \n",
    "    print(\n",
    "        f\"CREMA_df:\\n{CREMA_df['labels'].value_counts()}\",\n",
    "        end=\"\\n\" + \"-\" * 100 + \"\\n\"\n",
    "    )\n",
    "    \n",
    "    return CREMA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T08:30:20.520969Z",
     "iopub.status.busy": "2022-03-11T08:30:20.520276Z",
     "iopub.status.idle": "2022-03-11T08:30:20.933385Z",
     "shell.execute_reply": "2022-03-11T08:30:20.932632Z",
     "shell.execute_reply.started": "2022-03-11T08:30:20.520929Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    SAVEE_df = load_data_SAVEE()\n",
    "    RAVDESS_df = load_data_RAVDESS()\n",
    "    TESS_df = load_data_TESS()\n",
    "    CREMA_df = load_data_CREMA()\n",
    "        \n",
    "    ref = pd.concat(\n",
    "        [SAVEE_df, RAVDESS_df, TESS_df, CREMA_df],\n",
    "        axis = 0\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        f\"Total:\\n{ref['labels'].value_counts()}\",\n",
    "        end=\"\\n\" + \"-\" *100 + \"\\n\"\n",
    "    )\n",
    "    \n",
    "    return ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T06:41:53.199553Z",
     "iopub.status.busy": "2021-11-15T06:41:53.19918Z",
     "iopub.status.idle": "2021-11-15T06:41:53.205295Z",
     "shell.execute_reply": "2021-11-15T06:41:53.20341Z",
     "shell.execute_reply.started": "2021-11-15T06:41:53.199506Z"
    }
   },
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(ref):\n",
    "    df = pd.DataFrame(columns=['feature'])\n",
    "\n",
    "    counter=0\n",
    "    for index,path in enumerate(ref.path):\n",
    "        X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "        df.loc[counter] = [mfccs]\n",
    "        counter=counter+1   \n",
    "    \n",
    "    ref.reset_index(inplace=True, drop=True)\n",
    "    df = pd.concat([ref,pd.DataFrame(df['feature'].values.tolist())],axis=1)\n",
    "    df=df.fillna(0)\n",
    "    \n",
    "    print(f\"df.shape -> {df.shape}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop(\n",
    "            ['path','labels','source'],axis=1\n",
    "        ),\n",
    "        df.labels,\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_test):\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "\n",
    "    X_train = (X_train - mean)/std\n",
    "    X_test = (X_test - mean)/std\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_test(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Logistic_regr\": LogisticRegression(),\n",
    "        \"Decision_tree\": DecisionTreeClassifier(),\n",
    "        \"Random_forest\": RandomForestClassifier(\n",
    "            max_features=\"log2\",\n",
    "            max_depth=10,\n",
    "            max_leaf_nodes=100,\n",
    "            min_samples_leaf=3,\n",
    "            min_samples_split=20,\n",
    "            n_estimators=22000,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    for model in models:\n",
    "        models[model].fit(X_train, y_train)\n",
    "        \n",
    "        print(\n",
    "            f\"{model} classification report:\\n\",\n",
    "            classification_report(y_test, models[model].predict(X_test)),\n",
    "            end=\"\\n\" + \"-\" * 100 + \"\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_model(X_train, X_test, y_train, y_test):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # one hot encode the target \n",
    "    lb = LabelEncoder()\n",
    "    y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "    y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "    \n",
    "    with open(\"data_description.txt\", 'w') as f:\n",
    "        f.write(f\"{lb.classes_}\")\n",
    "    print(lb.classes_)\n",
    "    \n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "    \n",
    "    \n",
    "    # New model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(256, 8, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 8, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 8, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 8, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 8, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(64, 8, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 8, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(14))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "    \n",
    "    print(\"train_ncols\", X_train.shape[-1])\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    model_history=model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=16,\n",
    "        epochs=80,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_test))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T08:57:56.587868Z",
     "iopub.status.busy": "2022-03-11T08:57:56.587488Z",
     "iopub.status.idle": "2022-03-11T08:57:59.271095Z",
     "shell.execute_reply": "2022-03-11T08:57:59.270402Z",
     "shell.execute_reply.started": "2022-03-11T08:57:56.587777Z"
    }
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T08:57:59.273283Z",
     "iopub.status.busy": "2022-03-11T08:57:59.272406Z",
     "iopub.status.idle": "2022-03-11T09:06:44.835850Z",
     "shell.execute_reply": "2022-03-11T09:06:44.835084Z",
     "shell.execute_reply.started": "2022-03-11T08:57:59.273244Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    ref = load_data()\n",
    "    df = feature_extraction(ref)\n",
    "    X_train, X_test, y_train, y_test = df_split(df)\n",
    "    \n",
    "    X_train, X_test = normalization(X_train, X_test)\n",
    "    baseline_test(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    model = seq_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE_df:\n",
      "male_neutral     120\n",
      "male_sad          60\n",
      "male_happy        60\n",
      "male_disgust      60\n",
      "male_fear         60\n",
      "male_surprise     60\n",
      "male_angry        60\n",
      "Name: labels, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RAVDESS_df:\n",
      "female_neutral     144\n",
      "male_neutral       144\n",
      "male_sad            96\n",
      "female_surprise     96\n",
      "female_happy        96\n",
      "male_fear           96\n",
      "male_happy          96\n",
      "female_sad          96\n",
      "female_disgust      96\n",
      "male_surprise       96\n",
      "male_disgust        96\n",
      "male_angry          96\n",
      "female_angry        96\n",
      "female_fear         96\n",
      "Name: labels, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TESS_df:\n",
      "female_surprise    400\n",
      "female_happy       400\n",
      "female_sad         400\n",
      "female_fear        400\n",
      "female_neutral     400\n",
      "female_disgust     400\n",
      "female_angry       400\n",
      "Name: labels, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CREMA_df:\n",
      "male_angry        671\n",
      "male_sad          671\n",
      "male_disgust      671\n",
      "male_fear         671\n",
      "male_happy        671\n",
      "female_happy      600\n",
      "female_sad        600\n",
      "female_fear       600\n",
      "female_disgust    600\n",
      "female_angry      600\n",
      "male_neutral      575\n",
      "female_neutral    512\n",
      "Name: labels, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total:\n",
      "female_happy       1096\n",
      "female_sad         1096\n",
      "female_fear        1096\n",
      "female_disgust     1096\n",
      "female_angry       1096\n",
      "female_neutral     1056\n",
      "male_neutral        839\n",
      "male_angry          827\n",
      "male_sad            827\n",
      "male_disgust        827\n",
      "male_fear           827\n",
      "male_happy          827\n",
      "female_surprise     496\n",
      "male_surprise       156\n",
      "Name: labels, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "df.shape -> (12162, 219)\n",
      "Logistic_regr classification report                  precision    recall  f1-score   support\n",
      "\n",
      "   female_angry       0.30      0.20      0.24       222\n",
      " female_disgust       0.31      0.36      0.33       218\n",
      "    female_fear       0.28      0.26      0.27       221\n",
      "   female_happy       0.25      0.26      0.25       239\n",
      " female_neutral       0.25      0.30      0.27       176\n",
      "     female_sad       0.26      0.28      0.27       227\n",
      "female_surprise       0.47      0.46      0.47       102\n",
      "     male_angry       0.29      0.49      0.37       171\n",
      "   male_disgust       0.14      0.13      0.14       152\n",
      "      male_fear       0.12      0.12      0.12       147\n",
      "     male_happy       0.17      0.14      0.16       177\n",
      "   male_neutral       0.19      0.16      0.17       175\n",
      "       male_sad       0.09      0.07      0.08       176\n",
      "  male_surprise       0.22      0.30      0.25        30\n",
      "\n",
      "       accuracy                           0.25      2433\n",
      "      macro avg       0.24      0.25      0.24      2433\n",
      "   weighted avg       0.24      0.25      0.24      2433\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Decision_tree classification report                  precision    recall  f1-score   support\n",
      "\n",
      "   female_angry       0.36      0.39      0.37       222\n",
      " female_disgust       0.37      0.37      0.37       218\n",
      "    female_fear       0.27      0.26      0.26       221\n",
      "   female_happy       0.36      0.36      0.36       239\n",
      " female_neutral       0.28      0.30      0.29       176\n",
      "     female_sad       0.41      0.37      0.39       227\n",
      "female_surprise       0.58      0.59      0.58       102\n",
      "     male_angry       0.36      0.35      0.36       171\n",
      "   male_disgust       0.14      0.16      0.15       152\n",
      "      male_fear       0.09      0.11      0.10       147\n",
      "     male_happy       0.18      0.17      0.18       177\n",
      "   male_neutral       0.18      0.15      0.17       175\n",
      "       male_sad       0.13      0.12      0.12       176\n",
      "  male_surprise       0.13      0.10      0.11        30\n",
      "\n",
      "       accuracy                           0.28      2433\n",
      "      macro avg       0.27      0.27      0.27      2433\n",
      "   weighted avg       0.28      0.28      0.28      2433\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Random_forest classification report                  precision    recall  f1-score   support\n",
      "\n",
      "   female_angry       0.48      0.41      0.44       222\n",
      " female_disgust       0.41      0.52      0.46       218\n",
      "    female_fear       0.57      0.30      0.40       221\n",
      "   female_happy       0.56      0.49      0.52       239\n",
      " female_neutral       0.50      0.41      0.45       176\n",
      "     female_sad       0.35      0.70      0.47       227\n",
      "female_surprise       0.68      0.71      0.69       102\n",
      "     male_angry       0.43      0.71      0.53       171\n",
      "   male_disgust       0.18      0.17      0.18       152\n",
      "      male_fear       0.15      0.10      0.12       147\n",
      "     male_happy       0.28      0.32      0.30       177\n",
      "   male_neutral       0.33      0.26      0.29       175\n",
      "       male_sad       0.25      0.08      0.12       176\n",
      "  male_surprise       0.23      0.20      0.21        30\n",
      "\n",
      "       accuracy                           0.40      2433\n",
      "      macro avg       0.39      0.38      0.37      2433\n",
      "   weighted avg       0.40      0.40      0.38      2433\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['female_angry' 'female_disgust' 'female_fear' 'female_happy'\n",
      " 'female_neutral' 'female_sad' 'female_surprise' 'male_angry'\n",
      " 'male_disgust' 'male_fear' 'male_happy' 'male_neutral' 'male_sad'\n",
      " 'male_surprise']\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 216, 256)          2304      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 216, 256)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 216, 256)          524544    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 216, 256)         1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 216, 256)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 216, 256)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 27, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 27, 128)           262272    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 27, 128)           131200    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 27, 128)           131200    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 27, 128)           131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 27, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 3, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 3, 64)             65600     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 3, 64)             0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 3, 64)             32832     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 3, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                2702      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 14)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,285,390\n",
      "Trainable params: 1,284,622\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "train_ncols 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "609/609 [==============================] - 72s 116ms/step - loss: 2.4212 - accuracy: 0.1778 - val_loss: 2.4091 - val_accuracy: 0.2314\n",
      "Epoch 2/80\n",
      "609/609 [==============================] - 82s 135ms/step - loss: 2.1800 - accuracy: 0.2635 - val_loss: 2.2173 - val_accuracy: 0.2737\n",
      "Epoch 3/80\n",
      "609/609 [==============================] - 83s 136ms/step - loss: 2.0665 - accuracy: 0.2944 - val_loss: 2.1285 - val_accuracy: 0.3206\n",
      "Epoch 4/80\n",
      "609/609 [==============================] - 79s 130ms/step - loss: 1.9871 - accuracy: 0.3224 - val_loss: 2.0688 - val_accuracy: 0.3333\n",
      "Epoch 5/80\n",
      "609/609 [==============================] - 74s 122ms/step - loss: 1.9230 - accuracy: 0.3441 - val_loss: 2.0176 - val_accuracy: 0.3498\n",
      "Epoch 6/80\n",
      "609/609 [==============================] - 74s 121ms/step - loss: 1.8629 - accuracy: 0.3649 - val_loss: 1.9823 - val_accuracy: 0.3584\n",
      "Epoch 7/80\n",
      "609/609 [==============================] - 74s 122ms/step - loss: 1.8321 - accuracy: 0.3690 - val_loss: 1.9400 - val_accuracy: 0.3720\n",
      "Epoch 8/80\n",
      "609/609 [==============================] - 78s 128ms/step - loss: 1.7890 - accuracy: 0.3889 - val_loss: 1.9146 - val_accuracy: 0.3818\n",
      "Epoch 9/80\n",
      "609/609 [==============================] - 83s 137ms/step - loss: 1.7625 - accuracy: 0.3912 - val_loss: 1.8835 - val_accuracy: 0.3806\n",
      "Epoch 10/80\n",
      "609/609 [==============================] - 82s 134ms/step - loss: 1.7291 - accuracy: 0.4066 - val_loss: 1.8611 - val_accuracy: 0.3925\n",
      "Epoch 11/80\n",
      "609/609 [==============================] - 83s 137ms/step - loss: 1.7120 - accuracy: 0.4063 - val_loss: 1.8228 - val_accuracy: 0.4065\n",
      "Epoch 12/80\n",
      "609/609 [==============================] - 82s 134ms/step - loss: 1.6857 - accuracy: 0.4153 - val_loss: 1.8252 - val_accuracy: 0.3938\n",
      "Epoch 13/80\n",
      "609/609 [==============================] - 82s 135ms/step - loss: 1.6725 - accuracy: 0.4221 - val_loss: 1.8052 - val_accuracy: 0.4053\n",
      "Epoch 14/80\n",
      "609/609 [==============================] - 78s 128ms/step - loss: 1.6515 - accuracy: 0.4272 - val_loss: 1.8003 - val_accuracy: 0.4147\n",
      "Epoch 15/80\n",
      "609/609 [==============================] - 94s 154ms/step - loss: 1.6290 - accuracy: 0.4316 - val_loss: 1.7919 - val_accuracy: 0.3962\n",
      "Epoch 16/80\n",
      "609/609 [==============================] - 96s 158ms/step - loss: 1.6190 - accuracy: 0.4423 - val_loss: 1.7942 - val_accuracy: 0.3995\n",
      "Epoch 17/80\n",
      "609/609 [==============================] - 92s 151ms/step - loss: 1.6087 - accuracy: 0.4407 - val_loss: 1.7727 - val_accuracy: 0.4036\n",
      "Epoch 18/80\n",
      "609/609 [==============================] - 93s 152ms/step - loss: 1.5911 - accuracy: 0.4452 - val_loss: 1.7796 - val_accuracy: 0.3942\n",
      "Epoch 19/80\n",
      "609/609 [==============================] - 93s 152ms/step - loss: 1.5791 - accuracy: 0.4534 - val_loss: 1.7383 - val_accuracy: 0.4201\n",
      "Epoch 20/80\n",
      "609/609 [==============================] - 100s 164ms/step - loss: 1.5607 - accuracy: 0.4637 - val_loss: 1.7372 - val_accuracy: 0.4135\n",
      "Epoch 21/80\n",
      "609/609 [==============================] - 101s 166ms/step - loss: 1.5565 - accuracy: 0.4626 - val_loss: 1.7213 - val_accuracy: 0.4209\n",
      "Epoch 22/80\n",
      "609/609 [==============================] - 100s 164ms/step - loss: 1.5389 - accuracy: 0.4694 - val_loss: 1.7169 - val_accuracy: 0.4291\n",
      "Epoch 23/80\n",
      "609/609 [==============================] - 89s 145ms/step - loss: 1.5341 - accuracy: 0.4654 - val_loss: 1.7251 - val_accuracy: 0.4217\n",
      "Epoch 24/80\n",
      "609/609 [==============================] - 84s 137ms/step - loss: 1.5216 - accuracy: 0.4716 - val_loss: 1.6994 - val_accuracy: 0.4299\n",
      "Epoch 25/80\n",
      "609/609 [==============================] - 83s 137ms/step - loss: 1.5171 - accuracy: 0.4733 - val_loss: 1.7010 - val_accuracy: 0.4229\n",
      "Epoch 26/80\n",
      "609/609 [==============================] - 83s 136ms/step - loss: 1.5016 - accuracy: 0.4825 - val_loss: 1.6888 - val_accuracy: 0.4242\n",
      "Epoch 27/80\n",
      "609/609 [==============================] - 83s 136ms/step - loss: 1.4989 - accuracy: 0.4816 - val_loss: 1.7042 - val_accuracy: 0.4201\n",
      "Epoch 28/80\n",
      "609/609 [==============================] - 83s 136ms/step - loss: 1.4818 - accuracy: 0.4850 - val_loss: 1.6779 - val_accuracy: 0.4258\n",
      "Epoch 29/80\n",
      "609/609 [==============================] - 82s 135ms/step - loss: 1.4714 - accuracy: 0.4947 - val_loss: 1.6818 - val_accuracy: 0.4270\n",
      "Epoch 30/80\n",
      "609/609 [==============================] - 82s 135ms/step - loss: 1.4612 - accuracy: 0.4931 - val_loss: 1.6667 - val_accuracy: 0.4361\n",
      "Epoch 31/80\n",
      "609/609 [==============================] - 81s 133ms/step - loss: 1.4545 - accuracy: 0.4953 - val_loss: 1.6931 - val_accuracy: 0.4147\n",
      "Epoch 32/80\n",
      "609/609 [==============================] - 83s 136ms/step - loss: 1.4503 - accuracy: 0.4992 - val_loss: 1.6736 - val_accuracy: 0.4373\n",
      "Epoch 33/80\n",
      "609/609 [==============================] - 81s 134ms/step - loss: 1.4344 - accuracy: 0.5040 - val_loss: 1.6667 - val_accuracy: 0.4394\n",
      "Epoch 34/80\n",
      "609/609 [==============================] - 83s 137ms/step - loss: 1.4246 - accuracy: 0.5063 - val_loss: 1.6503 - val_accuracy: 0.4464\n",
      "Epoch 35/80\n",
      "609/609 [==============================] - 82s 135ms/step - loss: 1.4268 - accuracy: 0.5108 - val_loss: 1.6410 - val_accuracy: 0.4406\n",
      "Epoch 36/80\n",
      "609/609 [==============================] - 94s 154ms/step - loss: 1.4112 - accuracy: 0.5146 - val_loss: 1.6721 - val_accuracy: 0.4258\n",
      "Epoch 37/80\n",
      "609/609 [==============================] - 100s 165ms/step - loss: 1.3966 - accuracy: 0.5212 - val_loss: 1.6489 - val_accuracy: 0.4410\n",
      "Epoch 38/80\n",
      "609/609 [==============================] - 95s 156ms/step - loss: 1.3944 - accuracy: 0.5207 - val_loss: 1.6840 - val_accuracy: 0.4155\n",
      "Epoch 39/80\n",
      "609/609 [==============================] - 99s 162ms/step - loss: 1.3815 - accuracy: 0.5246 - val_loss: 1.6404 - val_accuracy: 0.4414\n",
      "Epoch 40/80\n",
      "609/609 [==============================] - 97s 159ms/step - loss: 1.3696 - accuracy: 0.5318 - val_loss: 1.6265 - val_accuracy: 0.4464\n",
      "Epoch 41/80\n",
      "609/609 [==============================] - 99s 162ms/step - loss: 1.3624 - accuracy: 0.5323 - val_loss: 1.6723 - val_accuracy: 0.4164\n",
      "Epoch 42/80\n",
      "609/609 [==============================] - 96s 157ms/step - loss: 1.3656 - accuracy: 0.5275 - val_loss: 1.6515 - val_accuracy: 0.4246\n",
      "Epoch 43/80\n",
      "609/609 [==============================] - 105s 172ms/step - loss: 1.3472 - accuracy: 0.5346 - val_loss: 1.6565 - val_accuracy: 0.4205\n",
      "Epoch 44/80\n",
      "609/609 [==============================] - 108s 178ms/step - loss: 1.3460 - accuracy: 0.5379 - val_loss: 1.5996 - val_accuracy: 0.4533\n",
      "Epoch 45/80\n",
      "609/609 [==============================] - 122s 200ms/step - loss: 1.3356 - accuracy: 0.5421 - val_loss: 1.6290 - val_accuracy: 0.4369\n",
      "Epoch 46/80\n",
      "609/609 [==============================] - 117s 191ms/step - loss: 1.3177 - accuracy: 0.5501 - val_loss: 1.6284 - val_accuracy: 0.4340\n",
      "Epoch 47/80\n",
      "609/609 [==============================] - 116s 190ms/step - loss: 1.3204 - accuracy: 0.5481 - val_loss: 1.6507 - val_accuracy: 0.4373\n",
      "Epoch 48/80\n",
      "609/609 [==============================] - 111s 182ms/step - loss: 1.3166 - accuracy: 0.5501 - val_loss: 1.6157 - val_accuracy: 0.4373\n",
      "Epoch 49/80\n",
      "609/609 [==============================] - 107s 176ms/step - loss: 1.2958 - accuracy: 0.5580 - val_loss: 1.6121 - val_accuracy: 0.4377\n",
      "Epoch 50/80\n",
      "609/609 [==============================] - 102s 167ms/step - loss: 1.2902 - accuracy: 0.5593 - val_loss: 1.6643 - val_accuracy: 0.4275\n",
      "Epoch 51/80\n",
      "609/609 [==============================] - 103s 169ms/step - loss: 1.2861 - accuracy: 0.5635 - val_loss: 1.6147 - val_accuracy: 0.4468\n",
      "Epoch 52/80\n",
      "609/609 [==============================] - 122s 200ms/step - loss: 1.2754 - accuracy: 0.5605 - val_loss: 1.6448 - val_accuracy: 0.4394\n",
      "Epoch 53/80\n",
      "609/609 [==============================] - 99s 163ms/step - loss: 1.2692 - accuracy: 0.5712 - val_loss: 1.6285 - val_accuracy: 0.4270\n",
      "Epoch 54/80\n",
      "609/609 [==============================] - 99s 163ms/step - loss: 1.2560 - accuracy: 0.5740 - val_loss: 1.6145 - val_accuracy: 0.4443\n",
      "Epoch 55/80\n",
      "609/609 [==============================] - 99s 162ms/step - loss: 1.2547 - accuracy: 0.5727 - val_loss: 1.6116 - val_accuracy: 0.4431\n",
      "Epoch 56/80\n",
      "609/609 [==============================] - 100s 164ms/step - loss: 1.2469 - accuracy: 0.5714 - val_loss: 1.6511 - val_accuracy: 0.4307\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609/609 [==============================] - 95s 156ms/step - loss: 1.2342 - accuracy: 0.5825 - val_loss: 1.6099 - val_accuracy: 0.4468\n",
      "Epoch 58/80\n",
      "609/609 [==============================] - 96s 157ms/step - loss: 1.2289 - accuracy: 0.5822 - val_loss: 1.6079 - val_accuracy: 0.4455\n",
      "Epoch 59/80\n",
      "609/609 [==============================] - 96s 158ms/step - loss: 1.2205 - accuracy: 0.5868 - val_loss: 1.6322 - val_accuracy: 0.4287\n",
      "Epoch 60/80\n",
      "609/609 [==============================] - 95s 157ms/step - loss: 1.2148 - accuracy: 0.5854 - val_loss: 1.6094 - val_accuracy: 0.4320\n",
      "Epoch 61/80\n",
      "609/609 [==============================] - 95s 157ms/step - loss: 1.2138 - accuracy: 0.5814 - val_loss: 1.6431 - val_accuracy: 0.4287\n",
      "Epoch 62/80\n",
      "609/609 [==============================] - 101s 166ms/step - loss: 1.2001 - accuracy: 0.5986 - val_loss: 1.6088 - val_accuracy: 0.4349\n",
      "Epoch 63/80\n",
      "609/609 [==============================] - 93s 153ms/step - loss: 1.1875 - accuracy: 0.5994 - val_loss: 1.5980 - val_accuracy: 0.4439\n",
      "Epoch 64/80\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 1.1772 - accuracy: 0.5997 - val_loss: 1.5923 - val_accuracy: 0.4410\n",
      "Epoch 65/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1671 - accuracy: 0.6023 - val_loss: 1.6211 - val_accuracy: 0.4275\n",
      "Epoch 66/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1667 - accuracy: 0.6093 - val_loss: 1.6203 - val_accuracy: 0.4328\n",
      "Epoch 67/80\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 1.1660 - accuracy: 0.6067 - val_loss: 1.6223 - val_accuracy: 0.4365\n",
      "Epoch 68/80\n",
      "609/609 [==============================] - 90s 149ms/step - loss: 1.1492 - accuracy: 0.6136 - val_loss: 1.5967 - val_accuracy: 0.4443\n",
      "Epoch 69/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1453 - accuracy: 0.6111 - val_loss: 1.6208 - val_accuracy: 0.4295\n",
      "Epoch 70/80\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 1.1365 - accuracy: 0.6165 - val_loss: 1.6073 - val_accuracy: 0.4427\n",
      "Epoch 71/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1263 - accuracy: 0.6189 - val_loss: 1.5862 - val_accuracy: 0.4439\n",
      "Epoch 72/80\n",
      "609/609 [==============================] - 93s 152ms/step - loss: 1.1177 - accuracy: 0.6281 - val_loss: 1.6121 - val_accuracy: 0.4353\n",
      "Epoch 73/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1098 - accuracy: 0.6287 - val_loss: 1.5897 - val_accuracy: 0.4472\n",
      "Epoch 74/80\n",
      "609/609 [==============================] - 92s 151ms/step - loss: 1.0997 - accuracy: 0.6306 - val_loss: 1.6611 - val_accuracy: 0.4196\n",
      "Epoch 75/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.1093 - accuracy: 0.6278 - val_loss: 1.6468 - val_accuracy: 0.4275\n",
      "Epoch 76/80\n",
      "609/609 [==============================] - 92s 151ms/step - loss: 1.0789 - accuracy: 0.6377 - val_loss: 1.6645 - val_accuracy: 0.4176\n",
      "Epoch 77/80\n",
      "609/609 [==============================] - 95s 155ms/step - loss: 1.0730 - accuracy: 0.6414 - val_loss: 1.6026 - val_accuracy: 0.4365\n",
      "Epoch 78/80\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 1.0699 - accuracy: 0.6393 - val_loss: 1.6016 - val_accuracy: 0.4386\n",
      "Epoch 79/80\n",
      "609/609 [==============================] - 100s 164ms/step - loss: 1.0572 - accuracy: 0.6434 - val_loss: 1.6376 - val_accuracy: 0.4299\n",
      "Epoch 80/80\n",
      "609/609 [==============================] - 95s 157ms/step - loss: 1.0599 - accuracy: 0.6442 - val_loss: 1.5844 - val_accuracy: 0.4328\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
